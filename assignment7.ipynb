{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731f8642b09d1ed1",
   "metadata": {},
   "source": [
    "# Assignment 7: object-oriented programming\n",
    "- **you will learn:** How to use subclassing when defining models\n",
    "- **task:**  See section 7.3 below\n",
    "- **deadline:** 12.01.2026\n",
    "- [classes in python](https://docs.python.org/3/tutorial/classes.html)\n",
    "- ðŸ“ **Reminder:** Sync your GitHub repository with the main course repository, update your project in PyCharm, and after completing the assignment, commit and push your changes back to GitHub.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "610dd16ab0e0295d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:54.496456Z",
     "start_time": "2025-12-15T13:44:54.491080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "Scikit learn version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"Scikit learn version:\", sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4414ecad1d0a78e",
   "metadata": {},
   "source": [
    "## **7.1 Subclassing a Base Model**\n",
    "\n",
    "- In machine learning libraries such as **scikit-learn**, predictive models (for example,  \n",
    "  [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html))  \n",
    "  are implemented as classes that **inherit from shared base classes**.\n",
    "- These base classes define a **common interface and internal structure**, ensuring that all models expose a consistent set of methods, most notably `.fit()` for model training and `.predict()` for inference.\n",
    "- This standardized object-oriented design enables **model interchangeability**: different algorithms can be substituted with minimal code changes, often requiring the modification of only a single line.\n",
    "- Such a unified framework greatly improves **maintainability, extensibility, and reproducibility**, which are essential properties for large-scale data science and machine learning workflows.\n",
    "- Further technical details can be found in the  \n",
    "  [scikit-learn developer documentation](https://scikit-learn.org/stable/developers/develop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b60c137cd794e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:55.337403Z",
     "start_time": "2025-12-15T13:44:55.331754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.8253613 , 16.17800946, 20.51150884, 14.13871564, 13.88380391])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# Generate synthetic regression data\n",
    "# --------------------------------------------------\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.linspace(0, 10, 100).reshape(-1, 1)   # feature matrix\n",
    "y = 3.0 + 2.5 * X.squeeze() + np.random.normal(0, 2, size=X.shape[0])  # target\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Create, fit, and evaluate model\n",
    "# --------------------------------------------------\n",
    "# NOTE: To use a different model (e.g. Ridge, Lasso, RandomForest),\n",
    "# only the following line typically needs to be changed.\n",
    "model = sk.linear_model.LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on unseen test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inspect first predictions\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279749e527c4eab1",
   "metadata": {},
   "source": [
    "- Similarly, the same standardized method structure is used for **data transformers** (e.g. scalers, encoders), which also expose a consistent interface.\n",
    "- In the following sections, we demonstrate how to **define custom models using subclassing**, following the same design principles.\n",
    "- This approach not only enables the creation of customized models by extending or modifying existing implementations, but it also represents the **primary programming paradigm for neural networks**, as will be illustrated in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2cb45bf001f5fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:56.329434Z",
     "start_time": "2025-12-15T13:44:56.326858Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Base model definition\n",
    "# ---------------------------------------------------------------------\n",
    "# Our models will implement the methods 'fit', 'predict', and 'summary'.\n",
    "# These methods define a common interface and must be overridden by\n",
    "# every concrete subclass.\n",
    "class BaseModel:\n",
    "    \"\"\"\n",
    "    Base class for all models.\n",
    "\n",
    "    This class defines a shared interface that all models must follow.\n",
    "    It is not intended to be used directly.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        raise NotImplementedError(\"fit() must be implemented by subclasses\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Generate predictions for input data.\"\"\"\n",
    "        raise NotImplementedError(\"predict() must be implemented by subclasses\")\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"Display a summary of the trained model.\"\"\"\n",
    "        raise NotImplementedError(\"summary() must be implemented by subclasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2fcb81a442dc490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:56.731437Z",
     "start_time": "2025-12-15T13:44:56.729137Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Simple baseline model\n",
    "# ---------------------------------------------------------------------\n",
    "class SimpleAverageModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Baseline model that always predicts the average of the training target.\n",
    "\n",
    "    This model completely ignores the input features and is often used\n",
    "    as a simple performance baseline.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mean_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = np.asarray(y)\n",
    "        self.mean_ = y.mean()\n",
    "        self.is_fitted = True\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted before prediction\")\n",
    "\n",
    "        # Predict the same value for all inputs\n",
    "        return np.full(shape=len(X), fill_value=self.mean_)\n",
    "\n",
    "    def summary(self):\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted before summary\")\n",
    "\n",
    "        print(\"Simple Average Model Summary\")\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"Predicted constant value (mean): {self.mean_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f7bb640082efa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:57.140621Z",
     "start_time": "2025-12-15T13:44:57.137908Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Linear regression model\n",
    "# ---------------------------------------------------------------------\n",
    "class LinearRegressionModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Simple linear regression using the closed-form least squares solution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()   # initialize BaseModel\n",
    "        self.beta_0 = None\n",
    "        self.beta_1 = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model using ordinary least squares.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        x_mean = X.mean()\n",
    "        y_mean = y.mean()\n",
    "\n",
    "        self.beta_1 = np.sum((X - x_mean) * (y - y_mean)) / np.sum((X - x_mean) ** 2)\n",
    "        self.beta_0 = y_mean - self.beta_1 * x_mean\n",
    "\n",
    "        self.is_fitted = True\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict values using the trained linear model.\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted before prediction\")\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        return self.beta_0 + self.beta_1 * X\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Print model parameters.\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted before summary\")\n",
    "\n",
    "        print(\"Linear Regression Model Summary\")\n",
    "        print(\"-------------------------------\")\n",
    "        print(f\"Intercept (beta_0): {self.beta_0:.4f}\")\n",
    "        print(f\"Slope     (beta_1): {self.beta_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1293c7b4ae497d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:57.583083Z",
     "start_time": "2025-12-15T13:44:57.580926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Summary\n",
      "-------------------------------\n",
      "Intercept (beta_0): 3.1289\n",
      "Slope     (beta_1): 2.3840\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 10, 50)\n",
    "y = 3.0 + 2.5 * X + np.random.normal(0, 2, size=len(X))\n",
    "\n",
    "# Create and train model\n",
    "model = LinearRegressionModel()  # you can replace with SimpleAverageModel()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Inspect parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d858feaaeb65951",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:58.075612Z",
     "start_time": "2025-12-15T13:44:58.073380Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Linear regression model in improved custom version\n",
    "# ---------------------------------------------------------------------\n",
    "class LinearRegressionWithStats(LinearRegressionModel):\n",
    "    \"\"\"\n",
    "    Linear regression with goodness-of-fit statistics.\n",
    "    \"\"\"\n",
    "\n",
    "    def r_squared(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute RÂ² score.\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise RuntimeError(\"Model must be fitted first\")\n",
    "\n",
    "        y = np.asarray(y)\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        ss_total = np.sum((y - y.mean()) ** 2)\n",
    "        ss_residual = np.sum((y - y_pred) ** 2)\n",
    "\n",
    "        return 1 - ss_residual / ss_total\n",
    "\n",
    "    def residuals(self, X, y):\n",
    "        \"\"\"\n",
    "        Return residuals y - y_hat.\n",
    "        \"\"\"\n",
    "        return y - self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a818abc57008fd41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:58.572138Z",
     "start_time": "2025-12-15T13:44:58.569905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Summary\n",
      "-------------------------------\n",
      "Intercept (beta_0): 3.1289\n",
      "Slope     (beta_1): 2.3840\n",
      "R^2 score: 0.9372\n"
     ]
    }
   ],
   "source": [
    "model_stats = LinearRegressionWithStats()\n",
    "model_stats.fit(X, y)\n",
    "\n",
    "model_stats.summary()\n",
    "\n",
    "r2 = model_stats.r_squared(X, y)\n",
    "print(f\"R^2 score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c60077f9cbdf0a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T13:44:58.901486Z",
     "start_time": "2025-12-15T13:44:58.898403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86454212, -0.38174809,  1.21382428,  2.98817361, -0.50252616])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect residuals\n",
    "res = model_stats.residuals(X, y)\n",
    "res[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca93c70d86b096",
   "metadata": {},
   "source": [
    "## 7.2 Subclassing for Neural Networks\n",
    "\n",
    "In PyTorch, creating custom neural network architectures is typically done by **subclassing `torch.nn.Module`**. This approach provides full control over the network layers, forward propagation, and any additional operations you might want to include.  \n",
    "\n",
    "### Why Subclass `nn.Module`?\n",
    "\n",
    "- Allows defining **custom architectures** beyond pre-built models.  \n",
    "- Provides a clear separation between **layers** and **forward computation**.  \n",
    "- Integrates with PyTorchâ€™s **autograd** for automatic differentiation, details are provided in **Data Science 2** course.  \n",
    "\n",
    "### Example: Two-Layer Perceptron (MLP)\n",
    "\n",
    "Below is an example of a **two-layer multilayer perceptron (MLP)** implemented for regression tasks. For further reference on MLPs, see [this tutorial](https://www.geeksforgeeks.org/deep-learning/multi-layer-perceptron-learning-in-tensorflow/).  \n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "class TwoLayerPerceptron(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Two-layer multilayer perceptron (MLP) for regression tasks.\n",
    "\n",
    "    Architecture:\n",
    "        Input -> Linear -> Tanh -> Linear -> Output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim=1, hidden_dim=10, output_dim=1):\n",
    "        \"\"\"\n",
    "        Initialize the network layers.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Number of input features.\n",
    "            hidden_dim (int): Number of neurons in the hidden layer.\n",
    "            output_dim (int): Number of output neurons.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hidden = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "        self.output = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of the network.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_dim)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions\n",
    "        \"\"\"\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d8c0e3d894844a",
   "metadata": {},
   "source": [
    "## 7.3 Homework: Subclassing in Data Science\n",
    "\n",
    "### Task Overview\n",
    "In this assignment, you will practice **subclassing** by extending a linear regression model. Your goal is to enhance the standard model with an option to apply a **logarithmic transformation** to the response variable (`y`).\n",
    "\n",
    "---\n",
    "\n",
    "### Your Task\n",
    "1. **Create a subclass** called `LinearRegressionModelWithTransformation` that inherits from `LinearRegressionModel`.\n",
    "\n",
    "2. **Constructor (`__init__`)**  \n",
    "   - Add a boolean parameter `use_log` to the constructor, defaulting to `False`.\n",
    "\n",
    "3. **Override the `fit` method**  \n",
    "   - If `use_log` is `True`, apply `np.log` to the target variable `y` before fitting.\n",
    "   - If any `y` values are non-positive, shift all values so they are positive and print a message indicating the shift.\n",
    "   - If `use_log` is `False`, fit the model normally.\n",
    "   - **Important:** Do not re-implement the computation of `beta_0` and `beta_1`. Instead, transform the data as needed and call the parent `.fit()` method using `super().fit(X, y_transformed)`.\n",
    "\n",
    "4. **Override the `predict` method**  \n",
    "   - Ensure predictions are consistent with the `use_log` parameter (i.e. if `use_log=True`, return exponentiated predictions so that outputs are on the original scale.)\n",
    "\n",
    "5. **`summary` method**  \n",
    "   - The `summary` method remains unchanged\n",
    "\n",
    "---\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2.7, 7.4, 20.1, 54.6, 148.4])  # exponential trend\n",
    "\n",
    "model_log = LinearRegressionModelWithTransformation(use_log=True)\n",
    "model_log.fit(X, y)\n",
    "print(\"Log-transformed predictions:\", model_log.predict([6, 7]))\n",
    "model_log.summary()\n",
    "\n",
    "model_plain = LinearRegressionModelWithTransformation(use_log=False)\n",
    "model_plain.fit(X, y)\n",
    "print(\"Normal predictions:\", model_plain.predict([6, 7]))\n",
    "model_plain.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716c09219bcfb343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModelWithTransformation(LinearRegressionModel):\n",
    "    \"\"\"\n",
    "    Linear regression model with feature transformation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_log=False):\n",
    "        super().__init__()\n",
    "        self.use_log: bool = use_log\n",
    "        self.shift: float = 0.0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = y.copy()\n",
    "        if self.use_log:\n",
    "            if np.any(y < 0):\n",
    "                print(\"Shifting y to be non-negative for log transformation.\")\n",
    "                self.shift = -np.min(y) + 1e-6\n",
    "                y = y + self.shift\n",
    "            y = np.log(y)\n",
    "        super().fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = super().predict(X)\n",
    "        if self.use_log:\n",
    "            y_pred = np.exp(y_pred)\n",
    "            y_pred = y_pred - self.shift\n",
    "        return super().predict(X)\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"Linear Regression Model with Transformation Summary\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(f\"Using log transformation: {self.use_log}\")\n",
    "        super().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9acedece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-transformed predictions: [6.00264126 7.00382856]\n",
      "Linear Regression Model with Transformation Summary\n",
      "--------------------------------------------------\n",
      "Using log transformation: True\n",
      "Linear Regression Model Summary\n",
      "-------------------------------\n",
      "Intercept (beta_0): -0.0045\n",
      "Slope     (beta_1): 1.0012\n",
      "\n",
      "Normal predictions: [148.22 182.08]\n",
      "Linear Regression Model with Transformation Summary\n",
      "--------------------------------------------------\n",
      "Using log transformation: False\n",
      "Linear Regression Model Summary\n",
      "-------------------------------\n",
      "Intercept (beta_0): -54.9400\n",
      "Slope     (beta_1): 33.8600\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2.7, 7.4, 20.1, 54.6, 148.4])  # exponential trend\n",
    "\n",
    "model_log = LinearRegressionModelWithTransformation(use_log=True)\n",
    "model_log.fit(X, y)\n",
    "print(\"Log-transformed predictions:\", model_log.predict([6, 7]))\n",
    "model_log.summary()\n",
    "\n",
    "print()\n",
    "\n",
    "model_plain = LinearRegressionModelWithTransformation(use_log=False)\n",
    "model_plain.fit(X, y)\n",
    "print(\"Normal predictions:\", model_plain.predict([6, 7]))\n",
    "model_plain.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee31ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifting y to be non-negative for log transformation.\n",
      "Log-transformed predictions: [ 7.52778889 10.02225547]\n",
      "Linear Regression Model with Transformation Summary\n",
      "--------------------------------------------------\n",
      "Using log transformation: True\n",
      "Linear Regression Model Summary\n",
      "-------------------------------\n",
      "Intercept (beta_0): -7.4390\n",
      "Slope     (beta_1): 2.4945\n",
      "\n",
      "Normal predictions: [151.86 188.28]\n",
      "Linear Regression Model with Transformation Summary\n",
      "--------------------------------------------------\n",
      "Using log transformation: False\n",
      "Linear Regression Model Summary\n",
      "-------------------------------\n",
      "Intercept (beta_0): -66.6600\n",
      "Slope     (beta_1): 36.4200\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([-2.7, -7.4, 20.1, 54.6, 148.4])  # exponential trend\n",
    "\n",
    "model_log = LinearRegressionModelWithTransformation(use_log=True)\n",
    "model_log.fit(X, y)\n",
    "print(\"Log-transformed predictions:\", model_log.predict([6, 7]))\n",
    "model_log.summary()\n",
    "\n",
    "print()\n",
    "\n",
    "model_plain = LinearRegressionModelWithTransformation(use_log=False)\n",
    "model_plain.fit(X, y)\n",
    "print(\"Normal predictions:\", model_plain.predict([6, 7]))\n",
    "model_plain.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
